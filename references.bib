
@article{winkler_individual_2022,
	title = {Individual users' participation on political {Facebook} pages},
	volume = {2},
	copyright = {Copyright (c) 2022 Yannick Winkler, Marko Bachl, Michael Scharkow},
	issn = {2673-8813},
	url = {https://journalqd.org/article/view/3513},
	doi = {10/gs6x22},
	abstract = {Social media platforms such as Facebook enable citizens to participate in politics by engaging with content from parties and politicians. Most research has described these activites by means of survey self-reports, smaller sample studies which combined surveys and digital trace data, or larger-scale aggregate digital trace data. The current literature lacks a large-scale descriptive account of individual users' interactions with political content. We analyze a large-scale collection of individual-level Facebook user data from the German federal election year 2017. The data contain millions of interactions by over 2.5 million unique users on 320 Facebook pages of major parties in Germany. They include almost all possible ways to publicly interact with content on these pages and as such cannot be collected today due to newer access restrictions. A large share of users participated only once, especially on the top politicians' pages, or interacted only with a single page. However, we also found a sizeable group of users who were active on many different pages even across party boundaries, and that these users were responsible for a majority of comments and reactions on almost all pages. In addition, there were substantial differences in user participation on the main national party pages and the ones of top politicians on the one hand, and the less prominent pages on the other hand. Our large-scale quantitative description provides context for previous and future smaller-scale in-depth analyses.},
	language = {en},
	urldate = {2023-11-28},
	journal = {Journal of Quantitative Description: Digital Media},
	author = {Winkler, Yannick and Bachl, Marko and Scharkow, Michael},
	month = aug,
	year = {2022},
	keywords = {social media, Facebook, political participation, digital traces, computational methods, individual user behavior},
	file = {Full Text PDF:/Users/bachlm83/Zotero/storage/8TN4L8RR/Winkler et al. - 2022 - Individual users' participation on political Faceb.pdf:application/pdf},
}

@book{haim_computational_2023,
	address = {Wiesbaden},
	series = {Studienbücher zur {Kommunikations}- und {Medienwissenschaft}},
	title = {Computational {Communication} {Science}: {Eine} {Einführung}},
	isbn = {978-3-658-40170-2 978-3-658-40171-9},
	shorttitle = {Computational {Communication} {Science}},
	url = {https://link.springer.com/10.1007/978-3-658-40171-9},
	language = {de},
	urldate = {2023-06-21},
	publisher = {Springer Fachmedien Wiesbaden},
	author = {Haim, Mario},
	year = {2023},
	doi = {10.1007/978-3-658-40171-9},
	file = {Haim - 2023 - Computational Communication Science Eine Einführu.pdf:/Users/bachlm83/Zotero/storage/NU2TKM3V/Haim - 2023 - Computational Communication Science Eine Einführu.pdf:application/pdf},
}

@article{bruns_after_2019,
	title = {After the ‘{APIcalypse}’: social media platforms and their fight against critical scholarly research},
	volume = {22},
	issn = {1369-118X},
	shorttitle = {After the ‘{APIcalypse}’},
	url = {https://doi.org/10.1080/1369118X.2019.1637447},
	doi = {10/gf8r25},
	abstract = {In the aftermath of the Cambridge Analytica controversy, social media platform providers such as Facebook and Twitter have severely restricted access to platform data via their Application Programming Interfaces (APIs). This has had a particularly critical effect on the ability of social media researchers to investigate phenomena such as abuse, hate speech, trolling, and disinformation campaigns, and to hold the platforms to account for the role that their affordances and policies might play in facilitating such dysfunction. Alternative data access frameworks, such as Facebook’s partnership with the controversial Social Science One initiative, represent an insufficient replacement for fully functional APIs, and the platform providers’ actions in responding to the Cambridge Analytica scandal raise suspicions that they have instrumentalised it to actively frustrate critical, independent, public interest scrutiny by scholars. Building on a critical review of Facebook’s public statements through its own platforms and the mainstream media, and of the scholarly responses these have drawn, this article outlines the societal implications of the ‘APIcalypse’, and reviews potential options for scholars in responding to it.},
	number = {11},
	urldate = {2024-01-12},
	journal = {Information, Communication \& Society},
	author = {Bruns, Axel},
	month = sep,
	year = {2019},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/1369118X.2019.1637447},
	keywords = {Application Programming Interface, Cambridge Analytica, Facebook, social media, Social Science One, Twitter},
	pages = {1544--1566},
}

@article{freelon_computational_2018,
	title = {Computational research in the post-{API} age},
	volume = {35},
	issn = {1058-4609},
	url = {https://doi.org/10.1080/10584609.2018.1477506},
	doi = {10/gfs6ng},
	number = {4},
	urldate = {2021-11-04},
	journal = {Political Communication},
	author = {Freelon, Deen},
	month = oct,
	year = {2018},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/10584609.2018.1477506},
	keywords = {social media, Facebook, Twitter, API, computational},
	pages = {665--668},
	file = {Full Text PDF:/Users/bachlm83/Zotero/storage/NYWBFQ6V/Freelon - 2018 - Computational Research in the Post-API Age.pdf:application/pdf;Snapshot:/Users/bachlm83/Zotero/storage/G222RHBS/10584609.2018.html:text/html},
}

@article{stoll_developing_2023,
	title = {Developing an incivility dictionary for {German} online discussions – a semi-automated approach combining human and artificial knowledge},
	volume = {17},
	issn = {1931-2458},
	url = {https://doi.org/10.1080/19312458.2023.2166028},
	doi = {10/gsnfdn},
	abstract = {Incivility in online discussions has become an important issue in political communication research. Instruments and tools for the automated analysis of uncivil content, however, are rare, especially for non-English user-generated text. In this study, we present a) an extensive dictionary (DIKI - Diktionär für Inzivilität, English: Dictionary for Incivility) to detect incivility in German-language online discussions, and b) a semi-automated two-step-approach that combines manual content analysis with automated keyword collection using a pre-trained word embedding model. We show that DIKI clearly outperforms comparable dictionaries that have been used as alternative instruments to measure incivility (e.g., the LIWC) as well as basic machine learning approaches to text classification. Further, we provide evidence that pre-trained word embeddings can fruitfully be employed in the explorative phase of creating dictionaries. Still, the manual evaluation of DIKI confirms that detecting complex and context-dependent forms of incivility remains challenging and constant update would be needed to maintain performance. Finally, the detailed documentation of the developing and evaluation process of DIKI may serve as a guideline for further research. We therefore provide DIKI as a freely available instrument that also will be applicable in a web interface for drag-and-drop data analysis (diki.limitedminds.org).},
	number = {2},
	urldate = {2023-10-17},
	journal = {Communication Methods and Measures},
	author = {Stoll, Anke and Wilms, Lena and Ziegele, Marc},
	month = apr,
	year = {2023},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/19312458.2023.2166028},
	pages = {131--149},
	file = {Full Text PDF:/Users/bachlm83/Zotero/storage/T3FK6ZQT/Stoll et al. - 2023 - Developing an Incivility Dictionary for German Onl.pdf:application/pdf},
}

@misc{tornberg_how_2023,
	title = {How to use {LLMs} for text analysis},
	url = {http://arxiv.org/abs/2307.13106},
	doi = {10.48550/arXiv.2307.13106},
	abstract = {This guide introduces Large Language Models (LLM) as a highly versatile text analysis method within the social sciences. As LLMs are easy-to-use, cheap, fast, and applicable on a broad range of text analysis tasks, ranging from text annotation and classification to sentiment analysis and critical discourse analysis, many scholars believe that LLMs will transform how we do text analysis. This how-to guide is aimed at students and researchers with limited programming experience, and offers a simple introduction to how LLMs can be used for text analysis in your own research project, as well as advice on best practices. We will go through each of the steps of analyzing textual data with LLMs using Python: installing the software, setting up the API, loading the data, developing an analysis prompt, analyzing the text, and validating the results. As an illustrative example, we will use the challenging task of identifying populism in political texts, and show how LLMs move beyond the existing state-of-the-art.},
	urldate = {2023-09-18},
	publisher = {arXiv},
	author = {Törnberg, Petter},
	month = jul,
	year = {2023},
	note = {arXiv:2307.13106 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/Users/bachlm83/Zotero/storage/63RHTCI2/Törnberg - 2023 - How to use LLMs for Text Analysis.pdf:application/pdf;arXiv.org Snapshot:/Users/bachlm83/Zotero/storage/LAL83HGX/2307.html:text/html},
}

@article{laurer_less_2023,
	title = {Less annotating, more classifying: {Addressing} the data scarcity issue of supervised machine learning with deep transfer learning and {BERT}-{NLI}},
	issn = {1047-1987, 1476-4989},
	shorttitle = {Less {Annotating}, {More} {Classifying}},
	url = {https://www.cambridge.org/core/journals/political-analysis/article/less-annotating-more-classifying-addressing-the-data-scarcity-issue-of-supervised-machine-learning-with-deep-transfer-learning-and-bertnli/05BB05555241762889825B080E097C27},
	doi = {10.1017/pan.2023.20},
	abstract = {Supervised machine learning is an increasingly popular tool for analyzing large political text corpora. The main disadvantage of supervised machine learning is the need for thousands of manually annotated training data points. This issue is particularly important in the social sciences where most new research questions require new training data for a new task tailored to the specific research question. This paper analyses how deep transfer learning can help address this challenge by accumulating “prior knowledge” in language models. Models like BERT can learn statistical language patterns through pre-training (“language knowledge”), and reliance on task-specific data can be reduced by training on universal tasks like natural language inference (NLI; “task knowledge”). We demonstrate the benefits of transfer learning on a wide range of eight tasks. Across these eight tasks, our BERT-NLI model fine-tuned on 100 to 2,500 texts performs on average 10.7 to 18.3 percentage points better than classical models without transfer learning. Our study indicates that BERT-NLI fine-tuned on 500 texts achieves similar performance as classical models trained on around 5,000 texts. Moreover, we show that transfer learning works particularly well on imbalanced data. We conclude by discussing limitations of transfer learning and by outlining new opportunities for political science research.},
	language = {en},
	urldate = {2023-09-18},
	journal = {Political Analysis},
	author = {Laurer, Moritz and Atteveldt, Wouter van and Casas, Andreu and Welbers, Kasper},
	month = jun,
	year = {2023},
	pages = {1--17},
	file = {Laurer et al. - 2023 - Less Annotating, More Classifying Addressing the .pdf:/Users/bachlm83/Zotero/storage/9ATNEY2H/Laurer et al. - 2023 - Less Annotating, More Classifying Addressing the .pdf:application/pdf},
}

@article{gilardi_chatgpt_2023,
	title = {{ChatGPT} outperforms crowd workers for text-annotation tasks},
	volume = {120},
	copyright = {Copyright © 2023 the Author(s). Published by PNAS.},
	url = {https://www.pnas.org/doi/abs/10.1073/pnas.2305016120},
	doi = {10.1073/pnas.2305016120},
	abstract = {Many NLP applications require manual text annotations for a variety of tasks, notably
to train classifiers or evaluate the performance of unsupervi...},
	language = {EN},
	number = {30},
	urldate = {2023-09-18},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Gilardi, Fabrizio and Alizadeh, Meysam and Kubli, Maël},
	month = jul,
	year = {2023},
	note = {Company: National Academy of Sciences
Distributor: National Academy of Sciences
Institution: National Academy of Sciences
Label: National Academy of Sciences
Publisher: Proceedings of the National Academy of Sciences},
	pages = {e2305016120},
	file = {Gilardi et al. - 2023 - ChatGPT outperforms crowd workers for text-annotat.pdf:/Users/bachlm83/Zotero/storage/AKGMNQQJ/Gilardi et al. - 2023 - ChatGPT outperforms crowd workers for text-annotat.pdf:application/pdf},
}

@misc{rathje_gpt_2023,
	title = {{GPT} is an effective tool for multilingual psychological text analysis},
	url = {https://psyarxiv.com/sekf5/},
	doi = {10.31234/osf.io/sekf5},
	abstract = {The social and behavioral sciences have been increasingly using automated text analysis to measure psychological constructs in text. We explore whether GPT, the large-language model underlying the artificial intelligence chatbot ChatGPT, can be used as a tool for automated psychological text analysis in various languages. Across 15 datasets (n = 31,789 manually annotated tweets and news headlines), we tested whether GPT-3.5 and GPT-4 can accurately detect psychological constructs (sentiment, discrete emotions, and offensiveness) across 12 languages (English, Arabic, Indonesian, and Turkish, as well as eight African languages including Swahili, Amharic, Yoruba and Kinyarwanda). We found that GPT performs much better than English-language dictionary-based text analysis (r = 0.66-0.75 for correlations between manual annotations and GPT-4, as opposed to r = 0.20-0.30 for correlations between manual annotations and dictionary methods). Further, GPT performs nearly as well as or better than several fine-tuned machine learning models, though GPT had poorer performance in African languages and in comparison to more recent fine-tuned models. Overall, GPT may be superior to many existing methods of automated text analysis, since it achieves relatively high accuracy across many languages, requires no training data, and is easy to use with simple prompts (e.g., “is this text negative?”) and little coding experience. We provide sample code for analyzing text with the GPT application programming interface. GPT and other large-language models may be the future of psychological text analysis, and may help facilitate more cross-linguistic research with understudied languages.},
	language = {en-us},
	urldate = {2023-09-18},
	publisher = {PsyArXiv},
	author = {Rathje, Steve and Mirea, Dan-Mircea and Sucholutsky, Ilia and Marjieh, Raja and Robertson, Claire and Bavel, Jay J. Van},
	month = may,
	year = {2023},
	keywords = {Emotion, Social and Behavioral Sciences, Artificial Intelligence, GPT, Large Language Models, Machine Learning, Social and Personality Psychology, Text Analysis},
	file = {Full Text PDF:/Users/bachlm83/Zotero/storage/6I68XC5T/Rathje et al. - 2023 - GPT is an effective tool for multilingual psycholo.pdf:application/pdf},
}
