@article{bachl_alternative_2018,
	title = {({Alternative}) media sources in {AfD}-centered {Facebook} discussions},
	volume = {7},
	issn = {2192-4007},
	doi = {10/ghhx99},
	abstract = {In diesem Bericht untersuche ich, welche (massenmedialen) Quellen im Jahr 2016 auf 122 AfD-nahen Facebook-Seiten geteilt wurden. Die Ergebnisse zeigen, dass die untersuchten Online-Diskussionen kein Mainstream-Medien-freier Raum waren. Die Online-Angebote von Welt und Focus waren die mit Abstand meistgeteilten Quellen und alle wichtigen Medienangebote waren vorhanden. Allerdings waren auch viele der Quellen, die in den Diskursen über eine alternativ-rechte (online) Medienlandschaft genannt werden, deutlich sichtbar. Zusätzlich wurden zahlreiche weniger bekannte Webseiten und YouTube-Kanäle geteilt, von denen sich viele explizit als gegen den (wahrgenommenen) politischen und medialen Mainstream positionierten. Der Vergleich von Partei- und Nutzer-Inhalten ergab leichte Unterschiede. Die Partei-Kommunikatoren bevorzugten intellektuell anmutende, rechts-konservative Quellen; die Nutzer teilten mit größerer Wahrscheinlichkeit kontroversere und weniger bekannte Quellen.},
	language = {de},
	number = {2},
	journal = {Studies in Communication and Media},
	author = {Bachl, Marko},
	year = {2018},
	pages = {128--142},
}

@book{haim_computational_2023,
	address = {Wiesbaden},
	series = {Studienbücher zur {Kommunikations}- und {Medienwissenschaft}},
	title = {Computational {Communication} {Science}: {Eine} {Einführung}},
	isbn = {978-3-658-40170-2 978-3-658-40171-9},
	shorttitle = {Computational {Communication} {Science}},
	url = {https://link.springer.com/10.1007/978-3-658-40171-9},
	language = {de},
	urldate = {2023-06-21},
	publisher = {Springer Fachmedien Wiesbaden},
	author = {Haim, Mario},
	year = {2023},
	doi = {10.1007/978-3-658-40171-9},
}

@article{bruns_after_2019,
	title = {After the ‘{APIcalypse}’: social media platforms and their fight against critical scholarly research},
	volume = {22},
	issn = {1369-118X},
	shorttitle = {After the ‘{APIcalypse}’},
	url = {https://doi.org/10.1080/1369118X.2019.1637447},
	doi = {10/gf8r25},
	abstract = {In the aftermath of the Cambridge Analytica controversy, social media platform providers such as Facebook and Twitter have severely restricted access to platform data via their Application Programming Interfaces (APIs). This has had a particularly critical effect on the ability of social media researchers to investigate phenomena such as abuse, hate speech, trolling, and disinformation campaigns, and to hold the platforms to account for the role that their affordances and policies might play in facilitating such dysfunction. Alternative data access frameworks, such as Facebook’s partnership with the controversial Social Science One initiative, represent an insufficient replacement for fully functional APIs, and the platform providers’ actions in responding to the Cambridge Analytica scandal raise suspicions that they have instrumentalised it to actively frustrate critical, independent, public interest scrutiny by scholars. Building on a critical review of Facebook’s public statements through its own platforms and the mainstream media, and of the scholarly responses these have drawn, this article outlines the societal implications of the ‘APIcalypse’, and reviews potential options for scholars in responding to it.},
	number = {11},
	urldate = {2024-01-12},
	journal = {Information, Communication \& Society},
	author = {Bruns, Axel},
	month = sep,
	year = {2019},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/1369118X.2019.1637447},
	keywords = {Application Programming Interface, Cambridge Analytica, Facebook, social media, Social Science One, Twitter},
	pages = {1544--1566},
}

@article{freelon_computational_2018,
	title = {Computational research in the post-{API} age},
	volume = {35},
	issn = {1058-4609},
	url = {https://doi.org/10.1080/10584609.2018.1477506},
	doi = {10/gfs6ng},
	number = {4},
	urldate = {2021-11-04},
	journal = {Political Communication},
	author = {Freelon, Deen},
	month = oct,
	year = {2018},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/10584609.2018.1477506},
	keywords = {social media, Facebook, Twitter, API, computational},
	pages = {665--668},
}

@article{stoll_developing_2023,
	title = {Developing an incivility dictionary for {German} online discussions – a semi-automated approach combining human and artificial knowledge},
	volume = {17},
	issn = {1931-2458},
	url = {https://doi.org/10.1080/19312458.2023.2166028},
	doi = {10/gsnfdn},
	abstract = {Incivility in online discussions has become an important issue in political communication research. Instruments and tools for the automated analysis of uncivil content, however, are rare, especially for non-English user-generated text. In this study, we present a) an extensive dictionary (DIKI - Diktionär für Inzivilität, English: Dictionary for Incivility) to detect incivility in German-language online discussions, and b) a semi-automated two-step-approach that combines manual content analysis with automated keyword collection using a pre-trained word embedding model. We show that DIKI clearly outperforms comparable dictionaries that have been used as alternative instruments to measure incivility (e.g., the LIWC) as well as basic machine learning approaches to text classification. Further, we provide evidence that pre-trained word embeddings can fruitfully be employed in the explorative phase of creating dictionaries. Still, the manual evaluation of DIKI confirms that detecting complex and context-dependent forms of incivility remains challenging and constant update would be needed to maintain performance. Finally, the detailed documentation of the developing and evaluation process of DIKI may serve as a guideline for further research. We therefore provide DIKI as a freely available instrument that also will be applicable in a web interface for drag-and-drop data analysis (diki.limitedminds.org).},
	number = {2},
	urldate = {2023-10-17},
	journal = {Communication Methods and Measures},
	author = {Stoll, Anke and Wilms, Lena and Ziegele, Marc},
	month = apr,
	year = {2023},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/19312458.2023.2166028},
	pages = {131--149},
}

@misc{tornberg_best_2024,
	title = {Best practices for text annotation with large language models},
	url = {http://arxiv.org/abs/2402.05129},
	doi = {gtn9qf},
	abstract = {Large Language Models (LLMs) have ushered in a new era of text annotation, as their ease-of-use, high accuracy, and relatively low costs have meant that their use has exploded in recent months. However, the rapid growth of the field has meant that LLM-based annotation has become something of an academic Wild West: the lack of established practices and standards has led to concerns about the quality and validity of research. Researchers have warned that the ostensible simplicity of LLMs can be misleading, as they are prone to bias, misunderstandings, and unreliable results. Recognizing the transformative potential of LLMs, this paper proposes a comprehensive set of standards and best practices for their reliable, reproducible, and ethical use. These guidelines span critical areas such as model selection, prompt engineering, structured prompting, prompt stability analysis, rigorous model validation, and the consideration of ethical and legal implications. The paper emphasizes the need for a structured, directed, and formalized approach to using LLMs, aiming to ensure the integrity and robustness of text annotation practices, and advocates for a nuanced and critical engagement with LLMs in social scientific research.},
	urldate = {2024-03-03},
	publisher = {arXiv},
	author = {Törnberg, Petter},
	month = feb,
	year = {2024},
	note = {arXiv:2402.05129 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/Users/bachlm83/Zotero/storage/ZF9GNHEM/Törnberg - 2024 - Best Practices for Text Annotation with Large Lang.pdf:application/pdf;arXiv.org Snapshot:/Users/bachlm83/Zotero/storage/MFGPHBKD/2402.html:text/html},
}

@article{laurer_less_2023,
	title = {Less annotating, more classifying: {Addressing} the data scarcity issue of supervised machine learning with deep transfer learning and {BERT}-{NLI}},
	issn = {1047-1987, 1476-4989},
	shorttitle = {Less {Annotating}, {More} {Classifying}},
	url = {https://www.cambridge.org/core/journals/political-analysis/article/less-annotating-more-classifying-addressing-the-data-scarcity-issue-of-supervised-machine-learning-with-deep-transfer-learning-and-bertnli/05BB05555241762889825B080E097C27},
	doi = {10.1017/pan.2023.20},
	abstract = {Supervised machine learning is an increasingly popular tool for analyzing large political text corpora. The main disadvantage of supervised machine learning is the need for thousands of manually annotated training data points. This issue is particularly important in the social sciences where most new research questions require new training data for a new task tailored to the specific research question. This paper analyses how deep transfer learning can help address this challenge by accumulating “prior knowledge” in language models. Models like BERT can learn statistical language patterns through pre-training (“language knowledge”), and reliance on task-specific data can be reduced by training on universal tasks like natural language inference (NLI; “task knowledge”). We demonstrate the benefits of transfer learning on a wide range of eight tasks. Across these eight tasks, our BERT-NLI model fine-tuned on 100 to 2,500 texts performs on average 10.7 to 18.3 percentage points better than classical models without transfer learning. Our study indicates that BERT-NLI fine-tuned on 500 texts achieves similar performance as classical models trained on around 5,000 texts. Moreover, we show that transfer learning works particularly well on imbalanced data. We conclude by discussing limitations of transfer learning and by outlining new opportunities for political science research.},
	language = {en},
	urldate = {2023-09-18},
	journal = {Political Analysis},
	author = {Laurer, Moritz and Atteveldt, Wouter van and Casas, Andreu and Welbers, Kasper},
	month = jun,
	year = {2023},
	pages = {1--17},
}

@article{gilardi_chatgpt_2023,
	title = {{ChatGPT} outperforms crowd workers for text-annotation tasks},
	volume = {120},
	copyright = {Copyright © 2023 the Author(s). Published by PNAS.},
	url = {https://www.pnas.org/doi/abs/10.1073/pnas.2305016120},
	doi = {10.1073/pnas.2305016120},
	abstract = {Many NLP applications require manual text annotations for a variety of tasks, notably
to train classifiers or evaluate the performance of unsupervi...},
	language = {EN},
	number = {30},
	urldate = {2023-09-18},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Gilardi, Fabrizio and Alizadeh, Meysam and Kubli, Maël},
	month = jul,
	year = {2023},
	note = {Company: National Academy of Sciences
Distributor: National Academy of Sciences
Institution: National Academy of Sciences
Label: National Academy of Sciences
Publisher: Proceedings of the National Academy of Sciences},
	pages = {e2305016120},
}


@article{heseltine_large_2024,
	title = {Large language models as a substitute for human experts in annotating political text},
	volume = {11},
	issn = {2053-1680},
	url = {https://doi.org/10.1177/20531680241236239},
	doi = {10/gtkhqr},
	abstract = {Large-scale text analysis has grown rapidly as a method in political science and beyond. To date, text-as-data methods rely on large volumes of human-annotated training examples, which place a premium on researcher resources. However, advances in large language models (LLMs) may make automated annotation increasingly viable. This paper tests the performance of GPT-4 across a range of scenarios relevant for analysis of political text. We compare GPT-4 coding with human expert coding of tweets and news articles across four variables (whether text is political, its negativity, its sentiment, and its ideology) and across four countries (the United States, Chile, Germany, and Italy). GPT-4 coding is highly accurate, especially for shorter texts such as tweets, correctly classifying texts up to 95\% of the time. Performance drops for longer news articles, and very slightly for non-English text. We introduce a ‘hybrid’ coding approach, in which disagreements of multiple GPT-4 runs are adjudicated by a human expert, which boosts accuracy. Finally, we explore downstream effects, finding that transformer models trained on hand-coded or GPT-4-coded data yield almost identical outcomes. Our results suggest that LLM-assisted coding is a viable and cost-efficient approach, although consideration should be given to task complexity.},
	language = {en},
	number = {1},
	urldate = {2024-03-03},
	journal = {Research \& Politics},
	author = {Heseltine, Michael and Clemm von Hohenberg, Bernhard},
	month = jan,
	year = {2024},
	note = {Publisher: SAGE Publications Ltd},
	pages = {20531680241236239},
}

@misc{bachl_computational_2024,
	title = {Computational text analysis},
	url = {https://osf.io/3yhu8},
	doi = {10.31219/osf.io/3yhu8},
	abstract = {Computational text analysis (CTA) comprises techniques for measuring the content of texts with the help of computer algorithms. The methods are discussed under various labels, such as text-as-data, automated content analysis, natural language processing, or text mining. The defining characteristic of a CTA technique is that once it is initially configured, the computational system performs the measurements independently without requiring any manual intervention or effort. The strength of CTA lies in its scalability, enabling the measurement of characteristics across vast amounts of text. As a result, CTA has seen widespread application in communication, related social sciences, and the digital humanities, with the increasing availability of digital or digitized, machine-readable texts.
We start this chapter with an overview of the historical development of CTA. We then systematize CTA along two dimensions: the representations of texts for the computational analysis and the supervision of the measurement process. While doing so, we provide some examples of popular techniques. The chapter ends with an outlook into the near future.},
	language = {en-us},
	urldate = {2024-10-09},
	publisher = {OSF},
	author = {Bachl, Marko and Scharkow, Michael},
	month = oct,
	year = {2024},
}